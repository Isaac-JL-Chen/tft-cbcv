{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow GPU connection problem\n",
    "\n",
    "Need to install tensorflow with pip. https://www.tensorflow.org/install/pip\n",
    "\n",
    "Since installing with conda, we cannot detect GPU with below command.\n",
    "\n",
    "https://www.tensorflow.org/guide/gpu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver: 2.10.0\n",
      "Num GPUs Available:  8\n",
      "Num GPUs Available:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "import tensorflow as tf2\n",
    "print ('tensorflow ver:', tf2.__version__)\n",
    "\n",
    "# Return a list of physical devices visible to the host runtime.\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num GPUs Available: \", len(tf2.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to assign gpu number first (after checking memory usage with 'nvidia-smi' on terminal)\n",
    "gpu_num = 0\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_num)\n",
    "\n",
    "# Specifies which PhysicalDevice objects are visible to the runtime. TensorFlow will only allocate memory and place operations on visible physical devices, as otherwise no LogicalDevice will be created on them. By default all discovered devices are marked as visible.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus, 'GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 09:39:31.352330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-28 09:39:41.959369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30975 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal cuDNN launch failure problem\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "InternalError                             Traceback (most recent call last)\n",
    "/nethome/jhan405/cbcv/tft_google_ver4/main.ipynb Cell 18 in <cell line: 2>()\n",
    "     10     model.cache_batched_data(valid, \"valid\", num_samples=valid_samples)\n",
    "     12 sess.run(tf.global_variables_initializer())\n",
    "---> 14 model.fit()\n",
    "\n",
    "File ~/cbcv/tft_google_ver4/libs/tft_model.py:1158, in TemporalFusionTransformer.fit(self, train_df, valid_df)\n",
    "   1154 val_data, val_labels, val_flags = _unpack(valid_data)\n",
    "   1156 all_callbacks = callbacks\n",
    "-> 1158 self.model.fit(\n",
    "   1159     x=data,\n",
    "   1160     y=np.concatenate([labels, labels, labels], axis=-1),\n",
    "   1161     sample_weight=active_flags,\n",
    "   1162     epochs=self.num_epochs,\n",
    "   1163     batch_size=self.minibatch_size,\n",
    "   1164     validation_data=(val_data,\n",
    "   1165                      np.concatenate([val_labels, val_labels, val_labels],\n",
    "   1166                                     axis=-1), val_flags),\n",
    "   1167     callbacks=all_callbacks,\n",
    "   1168     shuffle=True,\n",
    "   1169     use_multiprocessing=True,\n",
    "   1170     workers=self.n_multiprocessing_workers)\n",
    "   1172 # Load best checkpoint again\n",
    "   1173 tmp_checkpont = self.get_keras_saved_path(self._temp_folder)\n",
    "\n",
    "File /home/jhan405/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training_v1.py:777, in Model.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\n",
    "    774 self._check_call_args('fit')\n",
    "    776 func = self._select_training_loop(x)\n",
    "--> 777 return func.fit(\n",
    "    778     self,\n",
    "    779     x=x,\n",
    "    780     y=y,\n",
    "    781     batch_size=batch_size,\n",
    "    782     epochs=epochs,\n",
    "    783     verbose=verbose,\n",
    "    784     callbacks=callbacks,\n",
    "    785     validation_split=validation_split,\n",
    "    786     validation_data=validation_data,\n",
    "    787     shuffle=shuffle,\n",
    "    788     class_weight=class_weight,\n",
    "    789     sample_weight=sample_weight,\n",
    "    790     initial_epoch=initial_epoch,\n",
    "    791     steps_per_epoch=steps_per_epoch,\n",
    "    792     validation_steps=validation_steps,\n",
    "    793     validation_freq=validation_freq,\n",
    "    794     max_queue_size=max_queue_size,\n",
    "    795     workers=workers,\n",
    "    796     use_multiprocessing=use_multiprocessing)\n",
    "\n",
    "File /home/jhan405/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py:641, in ArrayLikeTrainingLoop.fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\n",
    "    637     raise ValueError('`validation_steps` should not be specified if '\n",
    "    638                      '`validation_data` is None.')\n",
    "    639   val_x, val_y, val_sample_weights = None, None, None\n",
    "--> 641 return fit_loop(\n",
    "    642     model,\n",
    "    643     inputs=x,\n",
    "    644     targets=y,\n",
    "    645     sample_weights=sample_weights,\n",
    "    646     batch_size=batch_size,\n",
    "    647     epochs=epochs,\n",
    "    648     verbose=verbose,\n",
    "    649     callbacks=callbacks,\n",
    "    650     val_inputs=val_x,\n",
    "    651     val_targets=val_y,\n",
    "    652     val_sample_weights=val_sample_weights,\n",
    "    653     shuffle=shuffle,\n",
    "    654     initial_epoch=initial_epoch,\n",
    "    655     steps_per_epoch=steps_per_epoch,\n",
    "    656     validation_steps=validation_steps,\n",
    "    657     validation_freq=validation_freq,\n",
    "    658     steps_name='steps_per_epoch')\n",
    "\n",
    "File /home/jhan405/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py:377, in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\n",
    "    374 callbacks._call_batch_hook(mode, 'begin', batch_index, batch_logs)\n",
    "    376 # Get outputs.\n",
    "--> 377 batch_outs = f(ins_batch)\n",
    "    378 if not isinstance(batch_outs, list):\n",
    "    379   batch_outs = [batch_outs]\n",
    "\n",
    "File /home/jhan405/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/backend.py:4275, in GraphExecutionFunction.__call__(self, inputs)\n",
    "   4269 if (self._callable_fn is None or feed_arrays != self._feed_arrays or\n",
    "   4270     symbol_vals != self._symbol_vals or\n",
    "   4271     feed_symbols != self._feed_symbols or self.fetches != self._fetches or\n",
    "   4272     session != self._session):\n",
    "   4273   self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
    "-> 4275 fetched = self._callable_fn(*array_vals,\n",
    "   4276                             run_metadata=self.run_metadata)\n",
    "   4277 self._call_fetch_callbacks(fetched[-len(self._fetches):])\n",
    "   4278 output_structure = tf.nest.pack_sequence_as(\n",
    "   4279     self._outputs_structure,\n",
    "   4280     fetched[:len(self.outputs)],\n",
    "   4281     expand_composites=True)\n",
    "\n",
    "File /home/jhan405/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/client/session.py:1480, in BaseSession._Callable.__call__(self, *args, **kwargs)\n",
    "   1478 try:\n",
    "   1479   run_metadata_ptr = tf_session.TF_NewBuffer() if run_metadata else None\n",
    "-> 1480   ret = tf_session.TF_SessionRunCallable(self._session._session,\n",
    "   1481                                          self._handle, args,\n",
    "   1482                                          run_metadata_ptr)\n",
    "   1483   if run_metadata:\n",
    "   1484     proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n",
    "\n",
    "InternalError: 2 root error(s) found.\n",
    "  (0) INTERNAL: cuDNN launch failure : input shape ([1,16,160,1])\n",
    "\t [[{{node TemporalFusionTransformer/layer_normalization_2/FusedBatchNormV3}}]]\n",
    "\t [[TemporalFusionTransformer/dropout_10/cond/then/_150/dropout/Mul/_2045]]\n",
    "  (1) INTERNAL: cuDNN launch failure : input shape ([1,16,160,1])\n",
    "\t [[{{node TemporalFusionTransformer/layer_normalization_2/FusedBatchNormV3}}]]\n",
    "0 successful operations.\n",
    "0 derived errors ignored.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Just try decrease the batch size, it will work (If all the GPU memory is used(nvidia-smi)). Else do this os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'. I had same issue which got solved with this.\n",
    "\n",
    "https://github.com/DeepLabCut/DeepLabCut/issues/1\n",
    "\n",
    "`os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/isl-org/Open3D-ML/issues/292\n",
    "\n",
    "I faced this issue on Ubuntu 18.04, CUDA 11.0.3, cuDNN 8, Nvidia driver v470.103.01.\n",
    "\n",
    "I upgraded to CUDA 11.4.3 with cuDNN 8, the issue disappeared.\n",
    "\n",
    "=======\n",
    "\n",
    "This may be related to the TensorFlow issue tensorflow/tensorflow#45779\n",
    "and can be resolved by asking TensorFlow to allocate GPU memory only as needed:\n",
    "https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
    "\n",
    "One way to do this is by setting the environment variable TF_FORCE_GPU_ALLOW_GROWTH to true. For example:\n",
    "\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=true python -m pytest tests/test_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/jhan405/miniconda3/envs/tf-gpu:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "cudatoolkit               10.1.243             h6bb024c_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda list cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/jhan405/miniconda3/envs/tf-gpu:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "cudnn                     7.6.5                cuda10.1_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda list cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nvcc` not found.\n"
     ]
    }
   ],
   "source": [
    "%nvcc --vsersion\n",
    "\n",
    "# nvcc: NVIDIA (R) Cuda compiler driver\n",
    "# Copyright (c) 2005-2021 NVIDIA Corporation\n",
    "# Built on Mon_Oct_11_21:27:02_PDT_2021\n",
    "# Cuda compilation tools, release 11.4, V11.4.152\n",
    "# Build cuda_11.4.r11.4/compiler.30521435_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/dt9/usr/bin/gcc'), ('cuda_compute_capabilities', ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']), ('cuda_version', '11.2'), ('cudnn_version', '8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', True)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow message\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "```\n",
    "2023-02-12 21:07:41.004000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "\n",
    "2023-02-12 21:07:46.421928: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "\n",
    "2023-02-12 21:08:04.508297: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/home/jhan405/miniconda3/envs/google-tft-tf2/lib/\n",
    "\n",
    "2023-02-12 21:08:04.509132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/home/jhan405/miniconda3/envs/google-tft-tf2/lib/\n",
    "\n",
    "2023-02-12 21:08:04.509156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default_keras_session = tf.keras.backend.get_session()\n",
    "\n",
    "```\n",
    "WARNING:tensorflow:From /nethome/jhan405/cbcv/tft_google_ver4/jianlin-tft/script_train_fixed_params.py:99: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
    "\n",
    "2023-02-13 05:12:52.784585: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "\n",
    "2023-02-13 05:12:57.930672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17462 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.932025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30975 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.933497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30975 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.934443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30975 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.935380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30975 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.936340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30975 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.937437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30975 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
    "2023-02-13 05:12:57.938588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30975 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('google-tft-tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af27f8fb7b39dcff1eb9cb09807ccd06f439c3818b2eab6c2f857ad9f2b112fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
